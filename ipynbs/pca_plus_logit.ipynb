{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "# SciKit-Learn\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((7868, 76))\n",
    "Y_train = np.zeros((7868, 147))\n",
    "X_test = np.zeros((2705, 76))\n",
    "predictions = np.zeros((2705, 147))\n",
    "\n",
    "# Load X_train\n",
    "dir_string = '../data/train_feature_files'\n",
    "training_files = os.listdir(dir_string)\n",
    "\n",
    "for file in training_files:\n",
    "    file_path = dir_string + '/' + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    a = np.load(file_path)\n",
    "    a_summary = a['summary']\n",
    "    X_train[int(song_id_str)] = a_summary\n",
    "    \n",
    "# Load Y_train\n",
    "with open('../data/cal10k_train_data.csv', 'r') as y_train_file:\n",
    "    for line in y_train_file:\n",
    "        if 'id' not in line:\n",
    "            features_w_id = line.strip().split(',')\n",
    "            features_no_id = features_w_id[1:]\n",
    "            for idx in range(len(features_no_id)):\n",
    "                features_no_id[idx] = int(features_no_id[idx])\n",
    "            Y_train[int(features_w_id[0])] = np.array(features_no_id)\n",
    "            \n",
    "# Load X_test\n",
    "dir_string = '../data/test_feature_files/'\n",
    "testing_files = os.listdir(dir_string)\n",
    "\n",
    "for file in testing_files:\n",
    "    file_path = dir_string + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    data = np.load(file_path)\n",
    "    data_summary = data['summary']\n",
    "    X_test[int(song_id_str)] = data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Column 2 because fuck that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7868, 76)\n",
      "(2705, 76)\n"
     ]
    }
   ],
   "source": [
    "where_are_NaNs = np.isnan(X_train)\n",
    "X_train[where_are_NaNs] = 0\n",
    "where_are_NaNs = np.isnan(X_test)\n",
    "X_test[where_are_NaNs] = 0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do PCA (w/ K keeping 99% variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7868, 62)\n",
      "(2705, 62)\n"
     ]
    }
   ],
   "source": [
    "# Scale the Data for Train and Test set\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "\n",
    "# Perform Dimensionality reduction because fuckkkkkkkkk some of these dumbass features\n",
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_approx = pca.transform(X_train_scaled)\n",
    "print(X_train_approx.shape)\n",
    "X_test_approx = pca.transform(X_test_scaled)\n",
    "print(X_test_approx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 147 Logits for Each Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "genre_models = list()\n",
    "for i in range(147):  # For each genre\n",
    "    genre_model = LogisticRegression(solver='liblinear')\n",
    "    genre_model.fit(X_train_approx, Y_train[:,i])\n",
    "    genre_models.append(genre_model)\n",
    "    \n",
    "print(len(genre_models))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Testing Data for all 147 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.16169318e-03   5.47220032e-04   1.46417003e-01 ...,   8.52911028e-03\n",
      "    2.70904474e-03   1.16139427e-03]\n",
      " [  1.98945135e-03   1.17831297e-04   2.76674609e-03 ...,   2.45018212e-04\n",
      "    7.30310565e-04   2.04680447e-02]\n",
      " [  5.38803836e-02   2.01536354e-03   4.15018060e-02 ...,   4.28598186e-03\n",
      "    8.86172419e-03   3.80692105e-03]\n",
      " ..., \n",
      " [  1.95205435e-03   2.14800919e-02   6.76201201e-03 ...,   4.69014523e-03\n",
      "    4.17695736e-03   6.06008084e-03]\n",
      " [  6.01795203e-04   2.38817520e-02   1.51914567e-02 ...,   1.24282922e-02\n",
      "    5.35448848e-04   2.07086901e-04]\n",
      " [  6.25550439e-03   1.28913519e-03   7.39441591e-03 ...,   1.39868166e-03\n",
      "    1.39552589e-03   7.73781788e-02]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(147):\n",
    "    genre_prediction_prob = genre_models[i].predict_proba(X_test_approx)\n",
    "    predictions[:, i] = genre_prediction_prob[:,1]  # Get probability that it is class=1\n",
    "        \n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a CSV for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/cal10k_test_random_submission.csv', 'r')\n",
    "id_line = None\n",
    "for line in file:\n",
    "    if 'id' in line:\n",
    "        id_line = line\n",
    "ids = []\n",
    "for i in range(2705):\n",
    "    ids.append(int(i))\n",
    "predictions = np.insert(predictions, 0, ids, axis=1)\n",
    "string_predictions = []\n",
    "for song_idx in range(len(predictions)):\n",
    "    song = predictions[song_idx]\n",
    "    song_string = []\n",
    "    for genre_idx in range(len(song)):\n",
    "        if genre_idx != 0:\n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "        else: \n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "    string_predictions.append(song_string)\n",
    "with open('../data/fuck_this_project_sometimes_man.csv', 'w') as out_file:\n",
    "    out_file.write(id_line)\n",
    "    for song_array in string_predictions:\n",
    "        song_array[0] = str(int(float(song_array[0])))\n",
    "        out_file.write(\",\".join(song_array) + os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating this shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.90413028e-03   6.35661788e-06   3.51711131e-02 ...,   2.01218400e-03\n",
      "    9.37349362e-06   3.63976344e-02]\n",
      " [  4.28641394e-04   2.88837216e-05   2.77470180e-02 ...,   1.13898490e-03\n",
      "    1.06090562e-03   4.42270162e-04]\n",
      " [  9.99164611e-04   4.72838828e-06   1.50059174e-02 ...,   4.03653496e-03\n",
      "    2.85722605e-04   2.91386925e-03]\n",
      " ..., \n",
      " [  4.34333501e-04   6.37673799e-05   1.74543085e-02 ...,   1.19922678e-05\n",
      "    3.07606572e-03   1.64472038e-02]\n",
      " [  1.90203732e-04   9.45692211e-05   1.16950095e-02 ...,   5.62015572e-04\n",
      "    6.98205696e-04   1.40019376e-01]\n",
      " [  2.58452470e-03   3.17083508e-04   2.43683935e-02 ...,   4.19116767e-04\n",
      "    5.10110380e-03   4.38808959e-02]]\n"
     ]
    }
   ],
   "source": [
    "half_X_train_len = math.floor(len(X_train)/2)\n",
    "half_Y_train_len = math.floor(len(Y_train)/2)\n",
    "X_cv_train = X_train[0:half_X_train_len]\n",
    "Y_cv_train = Y_train[0:half_Y_train_len]\n",
    "X_cv_test = X_train[half_X_train_len:]\n",
    "Y_cv_test = Y_train[half_Y_train_len:]\n",
    "cv_predictions = np.zeros(Y_cv_test.shape)\n",
    "\n",
    "genre_models = list()\n",
    "for i in range(147):  # For each genre\n",
    "    genre_model = LogisticRegression(solver='liblinear')\n",
    "    genre_model.fit(X_cv_train, Y_cv_train[:,i])\n",
    "    genre_models.append(genre_model)\n",
    "\n",
    "\n",
    "for i in range(147):\n",
    "    genre_prediction_prob = genre_models[i].predict_proba(X_cv_test)\n",
    "    cv_predictions[:, i] = genre_prediction_prob[:,1]  # Get probability that it is class=1\n",
    "        \n",
    "print(cv_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3934, 147)\n",
      "0.851911722097\n"
     ]
    }
   ],
   "source": [
    "print(cv_predictions.shape)\n",
    "print(skl.metrics.roc_auc_score(Y_cv_test, cv_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

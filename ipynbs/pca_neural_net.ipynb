{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "# SciKit-Learn\n",
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((7868, 76))\n",
    "Y_train = np.zeros((7868, 147))\n",
    "X_test = np.zeros((2705, 76))\n",
    "predictions = np.zeros((2705, 147))\n",
    "\n",
    "# Load X_train\n",
    "dir_string = '../data/train_feature_files'\n",
    "training_files = os.listdir(dir_string)\n",
    "\n",
    "for file in training_files:\n",
    "    file_path = dir_string + '/' + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    a = np.load(file_path)\n",
    "    a_summary = a['summary']\n",
    "    X_train[int(song_id_str)] = a_summary\n",
    "    \n",
    "# Load Y_train\n",
    "with open('../data/cal10k_train_data.csv', 'r') as y_train_file:\n",
    "    for line in y_train_file:\n",
    "        if 'id' not in line:\n",
    "            features_w_id = line.strip().split(',')\n",
    "            features_no_id = features_w_id[1:]\n",
    "            for idx in range(len(features_no_id)):\n",
    "                features_no_id[idx] = int(features_no_id[idx])\n",
    "            Y_train[int(features_w_id[0])] = np.array(features_no_id)\n",
    "            \n",
    "# Load X_test\n",
    "dir_string = '../data/test_feature_files/'\n",
    "testing_files = os.listdir(dir_string)\n",
    "\n",
    "for file in testing_files:\n",
    "    file_path = dir_string + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    data = np.load(file_path)\n",
    "    data_summary = data['summary']\n",
    "    X_test[int(song_id_str)] = data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7868, 76)\n",
      "(2705, 76)\n"
     ]
    }
   ],
   "source": [
    "where_are_NaNs = np.isnan(X_train)\n",
    "X_train[where_are_NaNs] = 0\n",
    "where_are_NaNs = np.isnan(X_test)\n",
    "X_test[where_are_NaNs] = 0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7868, 62)\n",
      "(2705, 62)\n"
     ]
    }
   ],
   "source": [
    "# Scale the Data for Train and Test set\n",
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "X_test_scaled = preprocessing.scale(X_test)\n",
    "\n",
    "# Perform Dimensionality reduction because fuckkkkkkkkk some of these dumbass features\n",
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_approx = pca.transform(X_train_scaled)\n",
    "print(X_train_approx.shape)\n",
    "X_test_approx = pca.transform(X_test_scaled)\n",
    "print(X_test_approx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Multi-layer Perceptron (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(248, 248), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural_net = MLPClassifier(hidden_layer_sizes=(120,120), activation='logistic', solver='lbfgs') got 89%\n",
    "# neural_net = MLPClassifier(hidden_layer_sizes=(186,186), activation='logistic', solver='lbfgs') got 89% but better\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(248,248), activation='logistic', solver='lbfgs')\n",
    "neural_net.fit(X_train_approx, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.55056157e-03   1.43595276e-03   1.43480820e-02 ...,   8.49919857e-03\n",
      "    2.24365360e-03   1.25879112e-03]\n",
      " [  2.01260786e-05   1.28974080e-06   5.16671778e-04 ...,   8.34217966e-05\n",
      "    9.38354658e-06   4.44585488e-04]\n",
      " [  4.44369815e-03   1.34166275e-04   3.21877230e-02 ...,   1.34324671e-03\n",
      "    5.39572521e-04   1.29281649e-04]\n",
      " ..., \n",
      " [  1.60593287e-04   2.29503744e-02   2.21575840e-03 ...,   1.98121577e-03\n",
      "    1.85166674e-02   7.33457220e-05]\n",
      " [  2.23194396e-05   8.50176356e-03   1.76553361e-01 ...,   2.05473810e-03\n",
      "    7.67774875e-05   1.42679646e-08]\n",
      " [  8.74717745e-05   5.24558130e-05   2.44343306e-06 ...,   2.82291782e-04\n",
      "    3.97409839e-04   6.16579284e-03]]\n"
     ]
    }
   ],
   "source": [
    "predictions = neural_net.predict_proba(X_test_approx)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/cal10k_test_random_submission.csv', 'r')\n",
    "id_line = None\n",
    "for line in file:\n",
    "    if 'id' in line:\n",
    "        id_line = line\n",
    "ids = []\n",
    "for i in range(2705):\n",
    "    ids.append(int(i))\n",
    "predictions = np.insert(predictions, 0, ids, axis=1)\n",
    "string_predictions = []\n",
    "for song_idx in range(len(predictions)):\n",
    "    song = predictions[song_idx]\n",
    "    song_string = []\n",
    "    for genre_idx in range(len(song)):\n",
    "        if genre_idx != 0:\n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "        else: \n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "    string_predictions.append(song_string)\n",
    "with open('../data/will_pca_help_MLP_probably_not.csv', 'w') as out_file:\n",
    "    out_file.write(id_line)\n",
    "    for song_array in string_predictions:\n",
    "        song_array[0] = str(int(float(song_array[0])))\n",
    "        out_file.write(\",\".join(song_array) + os.linesep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

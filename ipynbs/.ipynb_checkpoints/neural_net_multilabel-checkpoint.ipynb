{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "#Skynet\n",
    "import sklearn as skl\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((7868, 76))\n",
    "Y_train = np.zeros((7868, 147))\n",
    "X_test = np.zeros((2705, 76))\n",
    "predictions = np.zeros((2705, 147))\n",
    "\n",
    "# Load X_train\n",
    "dir_string = '../data/train_feature_files'\n",
    "training_files = os.listdir(dir_string)\n",
    "\n",
    "for file in training_files:\n",
    "    file_path = dir_string + '/' + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    a = np.load(file_path)\n",
    "    a_summary = a['summary']\n",
    "    X_train[int(song_id_str)] = a_summary\n",
    "    \n",
    "# Load Y_train\n",
    "with open('../data/cal10k_train_data.csv', 'r') as y_train_file:\n",
    "    for line in y_train_file:\n",
    "        if 'id' not in line:\n",
    "            features_w_id = line.strip().split(',')\n",
    "            features_no_id = features_w_id[1:]\n",
    "            for idx in range(len(features_no_id)):\n",
    "                features_no_id[idx] = int(features_no_id[idx])\n",
    "            Y_train[int(features_w_id[0])] = np.array(features_no_id)\n",
    "            \n",
    "# Load X_test\n",
    "dir_string = '../data/test_feature_files/'\n",
    "testing_files = os.listdir(dir_string)\n",
    "\n",
    "for file in testing_files:\n",
    "    file_path = dir_string + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    data = np.load(file_path)\n",
    "    data_summary = data['summary']\n",
    "    X_test[int(song_id_str)] = data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7868, 76)\n",
      "(2705, 76)\n"
     ]
    }
   ],
   "source": [
    "where_are_NaNs = np.isnan(X_train)\n",
    "X_train[where_are_NaNs] = 0\n",
    "where_are_NaNs = np.isnan(X_test)\n",
    "X_test[where_are_NaNs] = 0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.04953433e+00  -1.82717419e+00  -3.14378223e-01 ...,  -7.78459164e-01\n",
      "   -6.15547973e-01   3.63916714e-02]\n",
      " [ -5.89573467e-01  -5.43698480e-01   1.26742646e+00 ...,   3.02933909e+00\n",
      "    6.36986019e+00  -3.53863479e-02]\n",
      " [ -8.71579002e-01  -1.45694081e+00   8.06538601e-01 ...,  -1.39196830e+00\n",
      "    7.20935543e-02   7.04298404e-01]\n",
      " ..., \n",
      " [ -6.80810552e-01   1.28278619e+00  -6.48520049e-01 ...,   1.12104502e+00\n",
      "    4.24172839e-03  -6.16879755e-01]\n",
      " [ -8.78688385e-01   4.17609241e-01  -1.75760504e-01 ...,   6.52454338e-01\n",
      "   -1.75135222e-01  -5.08273063e-01]\n",
      " [ -9.54521806e-01   4.17609241e-01   4.14536114e-01 ...,   1.37187461e-01\n",
      "   -1.69513068e-01  -5.52251472e-01]]\n"
     ]
    }
   ],
   "source": [
    "scaled_X = preprocessing.scale(X_train)\n",
    "scaled_test = preprocessing.scale(X_test)\n",
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(27, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(27, 2), random_state=1)\n",
    "genre_model.fit(scaled_X, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teach the robot how to love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0056245   0.01083739  0.05960931 ...,  0.00736552  0.01057328\n",
      "   0.00252812]\n",
      " [ 0.00207128  0.00068827  0.00083464 ...,  0.0018892   0.00353662\n",
      "   0.0218879 ]\n",
      " [ 0.0061763   0.0028434   0.00632428 ...,  0.00521109  0.00703503\n",
      "   0.022561  ]\n",
      " ..., \n",
      " [ 0.01432918  0.00942668  0.03530193 ...,  0.01175108  0.01236127\n",
      "   0.01981373]\n",
      " [ 0.00900983  0.02149535  0.14886359 ...,  0.01166951  0.01457515\n",
      "   0.0022697 ]\n",
      " [ 0.00383073  0.00119922  0.0017344  ...,  0.00311178  0.00481954\n",
      "   0.03177182]]\n"
     ]
    }
   ],
   "source": [
    "predictions = genre_model.predict_proba(scaled_test)\n",
    "        \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6228.28682447\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/cal10k_test_random_submission.csv', 'r')\n",
    "id_line = None\n",
    "for line in file:\n",
    "    if 'id' in line:\n",
    "        id_line = line\n",
    "ids = []\n",
    "for i in range(2705):\n",
    "    ids.append(int(i))\n",
    "predictions = np.insert(predictions, 0, ids, axis=1)\n",
    "string_predictions = []\n",
    "for song_idx in range(len(predictions)):\n",
    "    song = predictions[song_idx]\n",
    "    song_string = []\n",
    "    for genre_idx in range(len(song)):\n",
    "        if genre_idx != 0:\n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "        else: \n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "    string_predictions.append(song_string)\n",
    "with open('../data/skynet_will_rise_with_multilabel_shit.csv', 'w') as out_file:\n",
    "    out_file.write(id_line)\n",
    "    for song_array in string_predictions:\n",
    "        song_array[0] = str(int(float(song_array[0])))\n",
    "        out_file.write(\",\".join(song_array) + os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.70533621e-06   3.38135998e-06   5.50615417e-09 ...,   2.50640947e-05\n",
      "    3.57141381e-04   5.40106541e-03]\n",
      " [  7.61445256e-07   6.56751151e-07   2.79616909e-10 ...,   6.12246417e-06\n",
      "    1.56471704e-04   2.42759467e-03]\n",
      " [  8.84339963e-05   5.21006421e-05   8.45600768e-07 ...,   2.48155461e-04\n",
      "    1.36202354e-03   1.58435508e-02]\n",
      " ..., \n",
      " [  9.26271265e-04   5.80707498e-04   8.19741488e-05 ...,   1.63794763e-03\n",
      "    4.06466372e-03   2.32730994e-02]\n",
      " [  2.84602872e-04   1.60201919e-04   6.82471179e-06 ...,   6.23439608e-04\n",
      "    2.32873588e-03   2.25657291e-02]\n",
      " [  1.27349445e-03   7.95651274e-04   1.48029487e-04 ...,   2.10918239e-03\n",
      "    4.70722008e-03   2.51398493e-02]]\n"
     ]
    }
   ],
   "source": [
    "X_cv_train = X_train[0:-2000]\n",
    "Y_cv_train = Y_train[0:-2000]\n",
    "X_cv_test = X_train[-2000:]\n",
    "Y_cv_test = Y_train[-2000:]\n",
    "cv_predictions = np.zeros(Y_cv_test.shape)\n",
    "\n",
    "scaled_cv_X = preprocessing.scale(X_cv_train)\n",
    "scaled_cv_test = preprocessing.scale(X_cv_test)\n",
    "\n",
    "genre_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(27, 2), random_state=1)\n",
    "genre_model.fit(scaled_cv_X, Y_cv_train)\n",
    "\n",
    "cv_predictions = genre_model.predict_proba(scaled_cv_test)  # Get probability that it is class=1\n",
    "        \n",
    "print(cv_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 147)\n",
      "0.781023172152\n"
     ]
    }
   ],
   "source": [
    "print(cv_predictions.shape)\n",
    "print(skl.metrics.roc_auc_score(Y_cv_test, cv_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

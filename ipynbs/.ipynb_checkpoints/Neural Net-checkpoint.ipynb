{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "\n",
    "# SciKit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Optimization module in scipy\n",
    "from scipy import optimize\n",
    "\n",
    "#Skynet\n",
    "import sklearn as skl\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((7868, 76))\n",
    "Y_train = np.zeros((7868, 147))\n",
    "X_test = np.zeros((2705, 76))\n",
    "predictions = np.zeros((2705, 147))\n",
    "\n",
    "# Load X_train\n",
    "dir_string = '../data/Kaggle_Final/train_feature_files'\n",
    "training_files = os.listdir(dir_string)\n",
    "\n",
    "for file in training_files:\n",
    "    file_path = dir_string + '/' + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    a = np.load(file_path)\n",
    "    a_summary = a['summary']\n",
    "    X_train[int(song_id_str)] = a_summary\n",
    "    \n",
    "# Load Y_train\n",
    "with open('../data/Kaggle_Final/cal10k_train_data.csv', 'r') as y_train_file:\n",
    "    for line in y_train_file:\n",
    "        if 'id' not in line:\n",
    "            features_w_id = line.strip().split(',')\n",
    "            features_no_id = features_w_id[1:]\n",
    "            for idx in range(len(features_no_id)):\n",
    "                features_no_id[idx] = int(features_no_id[idx])\n",
    "            Y_train[int(features_w_id[0])] = np.array(features_no_id)\n",
    "            \n",
    "# Load X_test\n",
    "dir_string = '../data/Kaggle_Final/test_feature_files/'\n",
    "testing_files = os.listdir(dir_string)\n",
    "\n",
    "for file in testing_files:\n",
    "    file_path = dir_string + file\n",
    "    song_id_str = file_path.split('/')[-1].split('.')[0]\n",
    "    data = np.load(file_path)\n",
    "    data_summary = data['summary']\n",
    "    X_test[int(song_id_str)] = data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7868, 76)\n",
      "(2705, 76)\n"
     ]
    }
   ],
   "source": [
    "where_are_NaNs = np.isnan(X_train)\n",
    "X_train[where_are_NaNs] = 0\n",
    "where_are_NaNs = np.isnan(X_test)\n",
    "X_test[where_are_NaNs] = 0\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.04953433e+00 -1.82717419e+00 -3.14378223e-01 ... -7.78459164e-01\n",
      "  -6.15547973e-01  3.63916714e-02]\n",
      " [-5.89573467e-01 -5.43698480e-01  1.26742646e+00 ...  3.02933909e+00\n",
      "   6.36986019e+00 -3.53863479e-02]\n",
      " [-8.71579002e-01 -1.45694081e+00  8.06538601e-01 ... -1.39196830e+00\n",
      "   7.20935543e-02  7.04298404e-01]\n",
      " ...\n",
      " [-6.80810552e-01  1.28278619e+00 -6.48520049e-01 ...  1.12104502e+00\n",
      "   4.24172839e-03 -6.16879755e-01]\n",
      " [-8.78688385e-01  4.17609241e-01 -1.75760504e-01 ...  6.52454338e-01\n",
      "  -1.75135222e-01 -5.08273063e-01]\n",
      " [-9.54521806e-01  4.17609241e-01  4.14536114e-01 ...  1.37187461e-01\n",
      "  -1.69513068e-01 -5.52251472e-01]]\n"
     ]
    }
   ],
   "source": [
    "scaled_X = preprocessing.scale(X_train)\n",
    "scaled_test = preprocessing.scale(X_test)\n",
    "print(scaled_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "genre_models = list()\n",
    "for i in range(147):\n",
    "    genre_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(25, 2), random_state=1)\n",
    "    genre_model.fit(scaled_X, Y_train[:,i])\n",
    "    genre_models.append(genre_model)\n",
    "print(len(genre_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teach the robot how to love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97905917 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.97905917 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.97905917 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.97905917 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.97905917 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.97905917 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(147):\n",
    "    genre_prediction = genre_models[i].predict(X_test)\n",
    "    genre_prediction_prob = genre_models[i].predict_proba(X_test)\n",
    "    predictions[:, i] = genre_prediction_prob[:,1]  # Get probability that it is class=1\n",
    "        \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12827.330277677907\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/Kaggle_Final/cal10k_test_random_submission.csv', 'r')\n",
    "id_line = None\n",
    "for line in file:\n",
    "    if 'id' in line:\n",
    "        id_line = line\n",
    "ids = []\n",
    "for i in range(2705):\n",
    "    ids.append(int(i))\n",
    "predictions = np.insert(predictions, 0, ids, axis=1)\n",
    "string_predictions = []\n",
    "for song_idx in range(len(predictions)):\n",
    "    song = predictions[song_idx]\n",
    "    song_string = []\n",
    "    for genre_idx in range(len(song)):\n",
    "        if genre_idx != 0:\n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "        else: \n",
    "            song_string.append(str(predictions[song_idx, genre_idx]))\n",
    "    string_predictions.append(song_string)\n",
    "with open('../data/Kaggle_Final/skynet_will_rise.csv', 'w') as out_file:\n",
    "    out_file.write(id_line)\n",
    "    for song_array in string_predictions:\n",
    "        song_array[0] = str(int(float(song_array[0])))\n",
    "        out_file.write(\",\".join(song_array) + os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.27524661e-04 9.78629986e-19 5.64165184e-21 ... 9.20491919e-11\n",
      "  1.45547472e-19 1.48744568e-17]\n",
      " [2.93065744e-17 4.31783726e-43 2.17902993e-31 ... 8.13907740e-21\n",
      "  3.35772062e-27 4.34166210e-31]\n",
      " [1.35617390e-16 2.19896412e-41 1.55660915e-17 ... 1.22406882e-20\n",
      "  6.08756741e-24 1.09969740e-10]\n",
      " ...\n",
      " [3.32737088e-25 1.05074213e-15 9.02470949e-26 ... 5.79029978e-33\n",
      "  1.57059754e-22 8.81079147e-34]\n",
      " [8.01204885e-46 1.79309435e-48 5.90988215e-41 ... 1.13228423e-31\n",
      "  4.46828541e-54 1.26562543e-09]\n",
      " [3.02398804e-33 1.17043406e-26 3.34740789e-27 ... 2.30403919e-22\n",
      "  4.18458321e-07 2.43110366e-07]]\n"
     ]
    }
   ],
   "source": [
    "X_cv_train = X_train[0:-1000]\n",
    "Y_cv_train = Y_train[0:-1000]\n",
    "X_cv_test = X_train[-1000:]\n",
    "Y_cv_test = Y_train[-1000:]\n",
    "cv_predictions = np.zeros(Y_cv_test.shape)\n",
    "\n",
    "scaled_cv_X = preprocessing.scale(X_cv_train)\n",
    "scaled_cv_test = preprocessing.scale(X_cv_test)\n",
    "\n",
    "genre_models = list()\n",
    "for i in range(147):  # For each genre\n",
    "    genre_model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(76, 50), random_state=1)\n",
    "    genre_model.fit(scaled_cv_X, Y_cv_train[:,i])\n",
    "    genre_models.append(genre_model)\n",
    "\n",
    "\n",
    "for i in range(147):\n",
    "    genre_prediction_prob = genre_models[i].predict_proba(scaled_cv_test)\n",
    "    cv_predictions[:, i] = genre_prediction_prob[:,1]  # Get probability that it is class=1\n",
    "        \n",
    "print(cv_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 147)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-159c1340e0c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_cv_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[0;32m--> 120\u001b[0;31m                                  sample_weight=score_weight)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine_learning/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    325\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "print(cv_predictions.shape)\n",
    "print(skl.metrics.roc_auc_score(Y_cv_test, cv_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
